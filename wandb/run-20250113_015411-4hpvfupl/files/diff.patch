diff --git a/ai_scientist/generate_ideas.py b/ai_scientist/generate_ideas.py
index d5f4f97..dd9c0cc 100644
--- a/ai_scientist/generate_ideas.py
+++ b/ai_scientist/generate_ideas.py
@@ -3,6 +3,7 @@ import os
 import os.path as osp
 import time
 from typing import List, Dict, Union
+import weave
 
 import backoff
 import requests
@@ -73,6 +74,7 @@ ONLY INCLUDE "I am done" IF YOU ARE MAKING NO MORE CHANGES."""
 
 
 # GENERATE IDEAS
+@weave.op()
 def generate_ideas(
         base_dir,
         client,
@@ -175,6 +177,7 @@ def generate_ideas(
 
 
 # GENERATE IDEAS OPEN-ENDED
+@weave.op()
 def generate_next_idea(
         base_dir,
         client,
@@ -278,7 +281,7 @@ def on_backoff(details):
         f"calling function {details['target'].__name__} at {time.strftime('%X')}"
     )
 
-
+@weave.op()
 @backoff.on_exception(
     backoff.expo, requests.exceptions.HTTPError, on_backoff=on_backoff
 )
@@ -357,7 +360,7 @@ In <JSON>, respond in JSON format with ONLY the following field:
 A query will work best if you are able to recall the exact name of the paper you are looking for, or the authors.
 This JSON will be automatically parsed, so ensure the format is precise.'''
 
-
+@weave.op()
 def check_idea_novelty(
         ideas,
         base_dir,
diff --git a/ai_scientist/llm.py b/ai_scientist/llm.py
index 7811fb9..fb12479 100644
--- a/ai_scientist/llm.py
+++ b/ai_scientist/llm.py
@@ -14,8 +14,10 @@ AVAILABLE_LLMS = [
     "gpt-4o-mini-2024-07-18",
     "gpt-4o-2024-05-13",
     "gpt-4o-2024-08-06",
+    "gpt-4o-2024-11-20",
     "o1-preview-2024-09-12",
     "o1-mini-2024-09-12",
+    "o1-2024-12-17",
     "deepseek-coder-v2-0724",
     "llama3.1-405b",
     # Anthropic Claude models via Amazon Bedrock
@@ -52,6 +54,7 @@ def get_batch_responses_from_llm(
         "gpt-4o-2024-05-13",
         "gpt-4o-mini-2024-07-18",
         "gpt-4o-2024-08-06",
+        "gpt-4o-2024-11-20"
     ]:
         new_msg_history = msg_history + [{"role": "user", "content": msg}]
         response = client.chat.completions.create(
@@ -70,6 +73,22 @@ def get_batch_responses_from_llm(
         new_msg_history = [
             new_msg_history + [{"role": "assistant", "content": c}] for c in content
         ]
+    elif model in ["o1-preview-2024-09-12", "o1-mini-2024-09-12","o1-2024-12-17"]:
+        new_msg_history = msg_history + [{"role": "user", "content": msg}]
+        response = client.chat.completions.create(
+            model=model,
+            messages=[
+                {"role": "user", "content": system_message},
+                *new_msg_history,
+            ],
+            temperature=1,
+            max_completion_tokens=MAX_NUM_TOKENS,
+            n=1,
+            #stop=None,
+            seed=0,
+        )
+        content = response.choices[0].message.content
+        new_msg_history = new_msg_history + [{"role": "assistant", "content": content}]
     elif model == "deepseek-coder-v2-0724":
         new_msg_history = msg_history + [{"role": "user", "content": msg}]
         response = client.chat.completions.create(
@@ -180,6 +199,7 @@ def get_response_from_llm(
         "gpt-4o-2024-05-13",
         "gpt-4o-mini-2024-07-18",
         "gpt-4o-2024-08-06",
+        "gpt-4o-2024-11-20",
     ]:
         new_msg_history = msg_history + [{"role": "user", "content": msg}]
         response = client.chat.completions.create(
@@ -196,7 +216,7 @@ def get_response_from_llm(
         )
         content = response.choices[0].message.content
         new_msg_history = new_msg_history + [{"role": "assistant", "content": content}]
-    elif model in ["o1-preview-2024-09-12", "o1-mini-2024-09-12"]:
+    elif model in ["o1-preview-2024-09-12", "o1-mini-2024-09-12","o1-2024-12-17"]:
         new_msg_history = msg_history + [{"role": "user", "content": msg}]
         response = client.chat.completions.create(
             model=model,
@@ -300,7 +320,7 @@ def create_client(model):
     elif 'gpt' in model:
         print(f"Using OpenAI API with model {model}.")
         return openai.OpenAI(), model
-    elif model in ["o1-preview-2024-09-12", "o1-mini-2024-09-12"]:
+    elif model in ["o1-preview-2024-09-12", "o1-mini-2024-09-12","o1-2024-12-17"]:
         print(f"Using OpenAI API with model {model}.")
         return openai.OpenAI(), model
     elif model == "deepseek-coder-v2-0724":
diff --git a/ai_scientist/perform_experiments.py b/ai_scientist/perform_experiments.py
index bb8c248..5d6ffdc 100644
--- a/ai_scientist/perform_experiments.py
+++ b/ai_scientist/perform_experiments.py
@@ -4,6 +4,7 @@ import shutil
 import subprocess
 import sys
 from subprocess import TimeoutExpired
+import weave
 
 MAX_ITERS = 4
 MAX_RUNS = 5
@@ -27,6 +28,7 @@ You can then implement the next thing on your list."""
 
 
 # RUN EXPERIMENT
+@weave.op()
 def run_experiment(folder_name, run_num, timeout=7200):
     cwd = osp.abspath(folder_name)
     # COPY CODE SO WE CAN SEE IT.
@@ -85,6 +87,7 @@ If you are finished with experiments, respond with 'ALL_COMPLETED'."""
 
 
 # RUN PLOTTING
+@weave.op()
 def run_plotting(folder_name, timeout=600):
     cwd = osp.abspath(folder_name)
     # LAUNCH COMMAND
@@ -113,6 +116,7 @@ def run_plotting(folder_name, timeout=600):
 
 
 # PERFORM EXPERIMENTS
+@weave.op()
 def perform_experiments(idea, folder_name, coder, baseline_results) -> bool:
     ## RUN EXPERIMENT
     current_iter = 0
diff --git a/ai_scientist/perform_review.py b/ai_scientist/perform_review.py
index 4a6b9ae..462737f 100644
--- a/ai_scientist/perform_review.py
+++ b/ai_scientist/perform_review.py
@@ -9,6 +9,7 @@ from ai_scientist.llm import (
     get_batch_responses_from_llm,
     extract_json_between_markers,
 )
+import weave
 
 reviewer_system_prompt_base = (
     "You are an AI researcher who is reviewing a paper that was submitted to a prestigious ML venue."
@@ -122,7 +123,7 @@ In general, authors should be rewarded rather than punished for being up front a
     + template_instructions
 )
 
-
+@weave.op()
 def perform_review(
     text,
     model,
@@ -357,7 +358,7 @@ You are in charge of meta-reviewing a paper that was reviewed by {reviewer_count
 Your job is to aggregate the reviews into a single meta-review in the same format.
 Be critical and cautious in your decision, find consensus, and respect the opinion of all the reviewers."""
 
-
+@weave.op()
 def get_meta_review(model, client, temperature, reviews):
     # Write a meta-review from a set of individual reviews
     review_text = ""
@@ -382,7 +383,7 @@ Review {i + 1}/{len(reviews)}:
     meta_review = extract_json_between_markers(llm_review)
     return meta_review
 
-
+@weave.op()
 def perform_improvement(review, coder):
     improvement_prompt = '''The following review has been created for your research paper:
 """
diff --git a/ai_scientist/perform_writeup.py b/ai_scientist/perform_writeup.py
index 7dc9eeb..2364bf4 100644
--- a/ai_scientist/perform_writeup.py
+++ b/ai_scientist/perform_writeup.py
@@ -6,12 +6,15 @@ import re
 import shutil
 import subprocess
 from typing import Optional, Tuple
+import weave
+import wandb
 
 from ai_scientist.generate_ideas import search_for_papers
 from ai_scientist.llm import get_response_from_llm, extract_json_between_markers, create_client, AVAILABLE_LLMS
 
 
 # GENERATE LATEX
+@weave.op()
 def generate_latex(coder, folder_name, pdf_file, timeout=30, num_error_corrections=5):
     folder = osp.abspath(folder_name)
     cwd = osp.join(folder, "latex")  # Fixed potential issue with path
@@ -89,8 +92,9 @@ Pay attention to any accidental uses of HTML syntax, e.g. </end instead of \\end
         else:
             break
     compile_latex(cwd, pdf_file, timeout=timeout)
+    upload_to_wandb("written_paper", pdf_file)
 
-
+@weave.op()
 def compile_latex(cwd, pdf_file, timeout=30):
     print("GENERATING LATEX")
 
@@ -292,7 +296,7 @@ In <JSON>, respond in JSON format with the following fields:
 Do not select papers that are already in the `references.bib` file at the top of the draft, or if the same citation exists under a different name.
 This JSON will be automatically parsed, so ensure the format is precise."""
 
-
+@weave.op()
 def get_citation_aider_prompt(
         client, model, draft, current_round, total_rounds
 ) -> Tuple[Optional[str], bool]:
@@ -398,6 +402,7 @@ Ensure the citation is well-integrated into the text.'''
 
 
 # PERFORM WRITEUP
+@weave.op()
 def perform_writeup(
         idea, folder_name, coder, cite_client, cite_model, num_cite_rounds=20
 ):
@@ -511,7 +516,6 @@ First, re-think the Title if necessary. Keep this concise and descriptive of the
 
     generate_latex(coder, folder_name, f"{folder_name}/{idea['Name']}.pdf")
 
-
 if __name__ == "__main__":
     from aider.coders import Coder
     from aider.models import Model
@@ -570,3 +574,11 @@ if __name__ == "__main__":
             perform_writeup(idea, folder_name, coder, client, client_model)
         except Exception as e:
             print(f"Failed to perform writeup: {e}")
+
+@weave.op()
+def upload_to_wandb(artifact_name, pdf_path):
+    # Initialize a WandB run
+    artifact = wandb.Artifact(name=artifact_name, type="pdf")    
+    artifact.add_file(local_path=pdf_path, name=os.path.basename(pdf_path))
+    artifact.save()
+    print(f"Uploaded {pdf_path} to WandB as artifact '{artifact_name}'.")
diff --git a/launch_scientist.py b/launch_scientist.py
index 4e9e719..4ea8113 100644
--- a/launch_scientist.py
+++ b/launch_scientist.py
@@ -8,6 +8,7 @@ import shutil
 import sys
 import time
 import torch
+import weave
 from aider.coders import Coder
 from aider.io import InputOutput
 from aider.models import Model
@@ -82,6 +83,7 @@ def parse_arguments():
         default=50,
         help="Number of ideas to generate",
     )
+
     return parser.parse_args()
 
 
@@ -122,7 +124,7 @@ def worker(
         print(f"Completed idea: {idea['Name']}, Success: {success}")
     print(f"Worker {gpu_id} finished.")
 
-
+@weave.op()
 def do_idea(
         base_dir,
         results_dir,
@@ -283,10 +285,9 @@ def do_idea(
             sys.stderr = original_stderr
             log.close()
 
-
-if __name__ == "__main__":
+@weave.op()
+def run_ai_scientist():
     args = parse_arguments()
-
     # Check available GPUs and adjust parallel processes if necessary
     available_gpus = get_available_gpus(args.gpus)
     if args.parallel > len(available_gpus):
@@ -321,7 +322,6 @@ if __name__ == "__main__":
         json.dump(ideas, f, indent=4)
 
     novel_ideas = [idea for idea in ideas if idea["novel"]]
-    # novel_ideas = list(reversed(novel_ideas))
 
     if args.parallel > 0:
         print(f"Running {args.parallel} parallel processes")
@@ -377,3 +377,8 @@ if __name__ == "__main__":
                 print(f"Failed to evaluate idea {idea['Name']}: {str(e)}")
 
     print("All ideas evaluated.")
+
+
+if __name__ == "__main__":
+    weave.init(os.environ["WANDB_ENTITY"]+"/"+os.environ["WANDB_PROJECT"])
+    run_ai_scientist()
diff --git a/review_iclr_bench/iclr_analysis.py b/review_iclr_bench/iclr_analysis.py
index 40eb031..66de512 100644
--- a/review_iclr_bench/iclr_analysis.py
+++ b/review_iclr_bench/iclr_analysis.py
@@ -34,6 +34,7 @@ def parse_arguments():
             "gpt-4o-mini-2024-07-18",
             "gpt-4o-2024-05-13",
             "gpt-4o-2024-08-06",
+            "gpt-4o-2024-11-20",
             "llama-3-1-405b-instruct",
             "deepseek-coder-v2-0724",
             "claude-3-5-sonnet-20240620",
@@ -256,6 +257,7 @@ def review_single_paper(
         "gpt-4o-2024-05-13",
         "gpt-4o-mini-2024-07-18",
         "gpt-4o-2024-08-06",
+        "gpt-4o-2024-11-20",
     ]:
         import openai
 
diff --git a/templates/nanoGPT/ideas.json b/templates/nanoGPT/ideas.json
index 5458d98..1cdd10f 100644
--- a/templates/nanoGPT/ideas.json
+++ b/templates/nanoGPT/ideas.json
@@ -18,453 +18,75 @@
         "novel": true
     },
     {
-        "Name": "attention_diversity_regularization",
-        "Title": "Attention Diversity Regularization: Encouraging Diverse Context Window Utilization in Transformers",
-        "Experiment": "Modify the loss function to include a regularization term that encourages diversity in the attention weights, using a measure such as entropy or the ratio of the attention weights to their maximum value. Introduce a hyperparameter to control the strength of the regularization term. Compare the model's performance on tasks that require long-range dependency modeling with and without the regularization term.",
+        "Name": "sparse_attention",
+        "Title": "Sparse Attention: Enhancing Efficiency in Transformer Models through Selective Attention Mechanisms",
+        "Experiment": "Modify the CausalSelfAttention class to implement a sparse attention mechanism using a fixed block sparsity pattern. Implement this in the attention computation and ensure causal properties are maintained. Evaluate the model by comparing computational efficiency (e.g., training time, memory usage) and performance metrics (e.g., validation loss, token generation quality) with the baseline dense attention model.",
         "Interestingness": 7,
         "Feasibility": 6,
-        "Novelty": 5,
-        "novel": true
-    },
-    {
-        "Name": "ntm_augmented_transformer",
-        "Title": "Neural Turing Machine-Augmented Transformer: Improving Text Generation with External Memory",
-        "Experiment": "Implement a fixed-size external memory module that stores and retrieves information through attention mechanisms, and apply the model to the task of text generation. Evaluate the effectiveness of the model and compare it to other approaches.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 6,
-        "novel": false
-    },
-    {
-        "Name": "uncertainty_based_filtering",
-        "Title": "Uncertainty-Based Filtering: Reducing Hallucinations in Text Generation by Selecting High-Certainty Predictions",
-        "Experiment": "Modify the forward function of the GPT class to output a probability distribution over the possible next tokens. Compute a measure of uncertainty (e.g. entropy or variance) from this distribution, and use it to filter out predictions where the model is highly uncertain. Evaluate the effect of this filtering on the frequency of hallucinations in the generated text.",
-        "Interestingness": 8,
-        "Feasibility": 8,
         "Novelty": 6,
         "novel": true
     },
     {
-        "Name": "targeted_knowledge_distillation",
-        "Title": "Targeted Knowledge Distillation for Transformer-Based Language Models: A Study on Distilling Specific Aspects of Model Behavior",
-        "Experiment": "Modify the GPT model to create a smaller student model with fewer layers and/or smaller embedding dimensions. Train the student model to mimic specific aspects of the teacher model's behavior, such as next token prediction or coherent text generation. Explore different distillation techniques, including attention-based distillation and layer-wise distillation.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "fine_tuning_gpt",
-        "Title": "Fine-Tuning for Task Adaptation: A Study on Adapting Pre-Trained GPT Models to New Tasks",
-        "Experiment": "Fine-tune the pre-trained GPT model on a small amount of task-specific data, using a standard supervised learning objective. Evaluate the effectiveness of this approach on a range of tasks and datasets, using metrics such as accuracy and perplexity.",
-        "Interestingness": 8,
-        "Feasibility": 9,
+        "Name": "adaptive_dropout",
+        "Title": "Adaptive Dropout: Dynamic Regularization for Improved Training in Transformer Models",
+        "Experiment": "Modify the dropout layers in the GPT model to have adaptive dropout rates based on a heuristic strategy. For example, gradually decrease dropout rates as training loss decreases, or adjust dropout based on the moving average of gradient norms. Implement this in the CausalSelfAttention and MLP classes, ensuring stability. Compare training dynamics and final performance with the baseline static dropout model to evaluate effectiveness.",
+        "Interestingness": 7,
+        "Feasibility": 6,
         "Novelty": 6,
-        "novel": false
-    },
-    {
-        "Name": "training_data_ordering",
-        "Title": "The Impact of Training Data Ordering on Language Model Performance",
-        "Experiment": "Modify the get_batch function to create batches with different ordering schemes, such as randomizing the order of the training data or prioritizing more recent text. Evaluate the model's performance on these batches using metrics such as perplexity, accuracy, or F1-score, and repeat the experiment on multiple datasets.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "memory_buffer_transformer",
-        "Title": "Memory Buffer Transformer: Improving Long-Range Dependency Modeling with a Simple Memory Mechanism",
-        "Experiment": "Modify the GPT model to include a fixed-size memory buffer that stores the most recent input tokens. Use a modified attention mechanism to incorporate the memory buffer into the model's predictions. Evaluate the impact of memory buffer size on model performance.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "meta_attention_gpt",
-        "Title": "Meta-Learning for Adaptive Attention in GPT Models",
-        "Experiment": "Modify the GPT model to include a meta-learning component that adapts the model's attention mechanism to new tasks and datasets. Train the meta-learning component using an episodic training protocol with a limited number of examples per task, and evaluate the model's performance on a diverse range of tasks and datasets.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "word_dropout_auxiliary_task",
-        "Title": "Word Dropout Auxiliary Task: Improving Language Understanding through Multi-Task Learning",
-        "Experiment": "Modify the training loop to include a word dropout auxiliary task, where a certain percentage of words in the input text are randomly replaced with a [MASK] token. Train the model to reconstruct the original text by predicting the missing words, in parallel with the primary language modeling task.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "temporal_regularization",
-        "Title": "Temporal Regularization for Mitigating Catastrophic Forgetting in Language Models",
-        "Experiment": "Modify the training loop to include a temporal regularization term that encourages the model to maintain consistency in its predictions over time. Add a L1 or L2 penalty term to the loss function that measures the difference between the model's predictions at different time steps.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 7,
         "novel": true
     },
     {
-        "Name": "graph_augmented_gpt",
-        "Title": "Graph-Augmented GPT for Improved Entity Relationship Modeling",
-        "Experiment": "Modify the GPT model to incorporate a graph-based representation of entity relationships, using a graph convolutional network (GCN) or graph attention network (GAT) to augment the existing attention mechanisms.",
+        "Name": "dynamic_vocab_scaling",
+        "Title": "Dynamic Vocabulary Scaling: Optimizing Language Model Efficiency Through Adaptive Vocabulary Sizes",
+        "Experiment": "Introduce a staged approach to dynamically adjust the vocabulary size during training. Define specific checkpoints based on training epochs or loss plateaus where the vocabulary size should increase. Adjust the data pipeline and GPTConfig to support these changes. Evaluate the impact on training speed and model performance with a controlled subset of the dataset and model runs, comparing to a static vocabulary setup.",
         "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "bias_aware_gpt",
-        "Title": "Bias-Aware GPT: A Self-Aware Language Model for Mitigating Biases",
-        "Experiment": "Modify the GPT model to include a bias detection mechanism. This could involve training a separate module to identify biased language or using existing techniques such as adversarial training. Evaluate the effectiveness of the bias detection mechanism using the Bias in Bios dataset.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "multi_objective_gpt",
-        "Title": "Multi-Objective Optimization for GPT Models: A Study on Language Modeling and Sentiment Analysis",
-        "Experiment": "Modify the forward function of the GPT class to output predictions for language modeling and sentiment analysis. Define separate optimizers for each task and modify the configure_optimizers function to use a weighted sum of the individual task losses. Use a subset of the training data with sentiment annotations for the sentiment analysis task.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "attention_dropout_transformer",
-        "Title": "Attention Dropout Transformer: Regularizing the Model with Targeted Dropout",
-        "Experiment": "Modify the transformer model to use attention dropout, which randomly drops out attention weights during training. Investigate the use of attention dropout in combination with other regularization techniques, such as dropout and weight decay. Evaluate the model's performance on language modeling and text classification tasks, and compare the results with the baseline model.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "domain_knowledge_graph_gpt",
-        "Title": "Domain-Specific Knowledge Graph-Augmented GPT for Improved Reasoning and Inference",
-        "Experiment": "Modify the GPT model to incorporate a pre-constructed domain-specific knowledge graph. Use a graph attention network (GAT) to integrate the knowledge graph into the model's attention mechanism. Evaluate the model's performance on tasks that require reasoning and inference in the chosen domain.",
-        "Interestingness": 9,
-        "Feasibility": 8,
+        "Feasibility": 6,
         "Novelty": 7,
         "novel": true
     },
     {
-        "Name": "difficulty_aware_sampling",
-        "Title": "Difficulty-Aware Sampling for Language Modeling: A Study on Dynamic Learning Objectives",
-        "Experiment": "Modify the training loop to use a difficulty-aware sampling strategy for the training data. Assign a difficulty score to each data point and sample them based on their difficulty, with a bias towards the more challenging ones. Evaluate the effectiveness of this approach using a robust set of metrics.",
+        "Name": "multitask_learning",
+        "Title": "Multitask Learning: Enhancing Generalization in Language Models through Simultaneous Task Training",
+        "Experiment": "Modify the training loop to train a shared model with separate output heads for each dataset. Introduce a multitask loss function that aggregates the losses from each dataset head. Adjust the data pipeline to sample batches from each dataset and update the model parameters based on the aggregated loss. Evaluate the model by comparing its performance on individual datasets before and after the introduction of multitask training, analyzing improvements in generalization.",
         "Interestingness": 8,
-        "Feasibility": 9,
+        "Feasibility": 6,
         "Novelty": 7,
         "novel": true
     },
     {
-        "Name": "discrete_time_echo_state_gpt",
-        "Title": "Discrete-Time Echo State Networks for Efficient Temporal Modeling in GPT",
-        "Experiment": "Replace the existing RNN layers in the GPT model with DTESN layers. Explore using simplified versions of the DTESN layers, such as sparse or pruned DTESNs. Combine the DTESN layers with a hierarchical attention framework to attend to different levels of abstraction in the input data.",
+        "Name": "curriculum_learning",
+        "Title": "Curriculum Learning: Enhancing Model Training Through Structured Data Presentation",
+        "Experiment": "Modify the data loading mechanism to implement curriculum learning. Start training with simpler sequences (e.g., shorter lengths or more frequent characters) and gradually introduce more complex sequences as training progresses. This requires adjusting the get_batch function to control data complexity based on training iteration. Compare convergence speed, validation loss, and generalization performance with the baseline model.",
         "Interestingness": 8,
         "Feasibility": 7,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "input_complexity_adaptation",
-        "Title": "Input Complexity Adaptation for Efficient Language Modeling",
-        "Experiment": "Modify the attention mechanism to adapt based on input complexity, measured using perplexity or entropy. Evaluate the model's performance on complex tasks and compare the results with the baseline model.",
-        "Interestingness": 8,
-        "Feasibility": 8,
         "Novelty": 7,
         "novel": false
     },
     {
-        "Name": "linguistic_complexity_manipulation",
-        "Title": "Linguistic Complexity Manipulation for Language Models: A Study on Performance and Generalization",
-        "Experiment": "Modify the input data to increase or decrease its linguistic complexity, such as by adding or removing complex syntactic structures, idiomatic expressions, or domain-specific vocabulary. Introduce a linguistic complexity-aware objective function to penalize the model for producing outputs that exceed a certain level of linguistic complexity. Evaluate the model's performance on a range of tasks, including language modeling, text classification, and question answering.",
+        "Name": "knowledge_distillation",
+        "Title": "Knowledge Distillation: Enhancing Smaller Language Models with Teacher-Student Training",
+        "Experiment": "First, train a larger model to serve as the teacher. Save its logits for the training data. Then, train a smaller model (student) using a combined loss function: one part for matching the original targets and another for matching the teacher's soft targets. Modify the training loop to include the distillation loss. Compare the student model's performance and efficiency with the baseline model of similar size trained without distillation.",
         "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "temporal_knowledge_forgetting_gpt",
-        "Title": "Temporal Knowledge Forgetting in Language Models: A Study on Adapting to Sudden Changes in Data Distributions",
-        "Experiment": "Modify the GPT model to incorporate a temporal knowledge forgetting mechanism, where the model intentionally forgets knowledge that is no longer relevant or useful due to sudden changes in the data distribution. Introduce a new objective function that encourages the model to forget outdated knowledge, or modify the attention mechanism to focus on more recent information. Evaluate the model's performance on tasks that require adaptability to sudden changes in the data distribution.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "monte_carlo_confidence_aware_gpt",
-        "Title": "Monte Carlo Confidence-Aware GPT: Estimating Uncertainty via Dropout",
-        "Experiment": "Modify the GPT model to use Monte Carlo dropout to estimate the model's uncertainty. Train the model with dropout and then use the dropout weights to estimate the model's uncertainty at test time. Use the estimated uncertainty to modulate the loss function and improve the model's performance.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "calibrated_confidence_aware_gpt",
-        "Title": "Calibrated Confidence-Aware GPT: Estimating Uncertainty in Language Modeling",
-        "Experiment": "Modify the GPT model to output a confidence score along with its predictions. Add a new output layer to estimate the model's confidence in its predictions. Incorporate a calibration mechanism, such as temperature scaling or Platt scaling, to improve the accuracy of the confidence estimates. Add a robustness regularization term to the loss function to encourage conservative confidence estimates for out-of-distribution inputs.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "factual_knowledge_neurons",
-        "Title": "Identifying Factual Knowledge Neurons in Language Models",
-        "Experiment": "Modify the GPT model to include a knowledge neuron module that identifies which neurons are most responsible for storing factual information. Use techniques from explainable AI, such as saliency maps or feature importance scores, to identify the knowledge neurons. Evaluate the effectiveness of the knowledge neuron module on a benchmark such as TriviaQA or SQuAD.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "domain_adaptation_meta_learning",
-        "Title": "Domain Adaptation via Meta-Learning for Language Modeling",
-        "Experiment": "Modify the GPT model to include a meta-learning component that adapts the model to new domains or tasks. Train the model on a set of tasks that require it to adapt to new domains or tasks, and evaluate its performance on a range of language tasks, including language modeling and text classification.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "dual_scale_attention_gpt",
-        "Title": "Dual-Scale Attention in GPT: Capturing Long-Range Dependencies with Sparse Attention",
-        "Experiment": "Add a single additional attention layer to the GPT model that attends to a larger context window than the existing attention mechanism. Use a sparse attention mechanism, such as sparse self-attention or axial attention, to reduce computational complexity.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "multimodal_emotionally_intelligent_gpt",
-        "Title": "Multimodal Emotionally Intelligent GPT: Generating Text that Understands and Expresses Emotions",
-        "Experiment": "Modify the dataset to include emotional labels through sentiment analysis or emotional annotation. Use a multimodal approach to incorporate both text and emotional labels as input to the model. Fine-tune the model using a combination of language modeling and emotional intelligence objectives. Evaluate the model's performance using metrics such as emotional accuracy, empathy, and sentiment analysis.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "availability_heuristic_gpt",
-        "Title": "Availability Heuristic-Aware GPT: Simulating Human-Like Conversational Flow in Language Generation",
-        "Experiment": "Modify the GPT model's attention mechanism to incorporate the availability heuristic. Introduce a weighted attention layer that prioritizes recent or frequent events, and evaluate the generated text's conversational flow and coherence using a set of custom metrics.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "interpretable_dynamic_attention_gpt",
-        "Title": "Interpretable Dynamic Attention GPT: A Multi-Task Learning Approach to Adaptive Context Window Size",
-        "Experiment": "Modify the existing GPT model to incorporate a dynamic attention mechanism that uses a learned controller to adaptively adjust the context window size. Train the controller using a multi-task learning approach, where it is trained to predict both attention weights and auxiliary tasks such as part-of-speech tagging or named entity recognition. Evaluate the performance of the modified model on a range of tasks that require different types of attention.",
-        "Interestingness": 8,
         "Feasibility": 7,
         "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "recency_effect_gpt",
-        "Title": "Recency Effect-Aware GPT: Simulating Human-Like Decision-Making in Language Generation",
-        "Experiment": "Modify the attention mechanism in the GPT model to use a weighted attention layer that prioritizes recent input tokens, incorporating the recency effect. Evaluate the generated text's perplexity and BLEU score to assess the impact of the recency effect on the language model's performance.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "idiomatic_gpt",
-        "Title": "Idiomatic GPT: A Language Model with Idiom Recognition and Generation",
-        "Experiment": "Modify the GPT model to include an idiom recognition module that uses a combination of attention mechanisms and knowledge graphs to identify and generate idiomatic expressions.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "selective_forgetting_gpt",
-        "Title": "Selective Forgetting in GPT: A Novel Approach to Memory Consolidation",
-        "Experiment": "Modify the attention mechanism in the GPT model to include a forgetting component that gradually reduces the importance of older information over time. Evaluate the effectiveness of this mechanism using metrics such as recall from a longer context window or reduction in catastrophic forgetting.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "syntactic_complexity_analysis",
-        "Title": "Syntactic Complexity Analysis in Language Models",
-        "Experiment": "Modify the training data to include a syntactic complexity metric, such as the average sentence length or the number of clauses per sentence. Analyze the model's performance on different subsets of the training data with varying levels of syntactic complexity, compared to a control group trained on a random subset of the data.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "linguistic_difficulty_gpt",
-        "Title": "Linguistic Difficulty-Aware GPT: Using Linguistic Features to Predict Input Text Complexity",
-        "Experiment": "Add a linguistic difficulty estimation module to the GPT model, which predicts the difficulty of the input text based on linguistic features such as sentence length, syntactic complexity, and semantic ambiguity. Use the estimated difficulty to adjust the attention weights in the model, with more attention allocated to complex or difficult input texts. Evaluate the performance of the modified model on a range of input texts with varying levels of linguistic complexity.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "linguistic_complexity_aware_gpt",
-        "Title": "Linguistic Complexity-Aware GPT: Improving Performance on Complex Input Texts",
-        "Experiment": "Modify the attention mechanism to incorporate a linguistic complexity estimation module. Evaluate the performance of the modified model on language modeling tasks with varying levels of linguistic complexity.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "recency_effect_gpt",
-        "Title": "Incorporating the Recency Effect into Language Models for More Coherent and Context-Dependent Text Generation",
-        "Experiment": "Modify the attention mechanism in the GPT model to prioritize recent input tokens, using a new weighting scheme that decays the importance of input tokens over time. Evaluate the language model's performance on text generation tasks using metrics that specifically evaluate coherence and context-dependence.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "dynamic_attention_gpt",
-        "Title": "Dynamic Attention GPT: Adapting to Varying Levels of Cognitive Load",
-        "Experiment": "Modify the GPT model to use a dynamic attention mechanism that adjusts its attention weights based on the average sentence length of the input text. Evaluate the performance of the modified model on language modeling tasks such as text generation and language translation.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
         "novel": false
     },
     {
-        "Name": "primacy_effect_gpt",
-        "Title": "The Primacy Effect in Language Models: Exploring the Impact on Text Completion",
-        "Experiment": "Modify the GPT model to introduce a primacy effect, where the model is biased towards generating text that is overly influenced by the first few tokens of the input. Evaluate the performance of the modified model on a text completion task, using metrics such as perplexity, BLEU score, and novelty score.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "novelty_conditioned_gpt",
-        "Title": "Novelty-Conditioned GPT: Adjusting Language Generation based on Input Novelty",
-        "Experiment": "Train the GPT model to detect novel input sequences and adjust its language generation accordingly. Use a novelty detection module to identify novel input sequences and modify the output generation to be more diverse and creative when novelty is detected.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "availability_heuristic_gpt",
-        "Title": "Availability Heuristic in GPT: Exploring the Impact of Recent Information on Language Generation",
-        "Experiment": "Modify the attention mechanism in the GPT model to give more weight to recently or frequently encountered information. Evaluate the performance of the modified model on a range of tasks, including language modeling, text generation, and text classification.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "frequency_based_forgetting_gpt",
-        "Title": "Frequency-Based Forgetting in GPT: Exploring the Impact of Forgetting on Language Model Performance",
-        "Experiment": "Modify the GPT model to incorporate a frequency-based forgetting mechanism that forgets input tokens during training. Train the model with this forgetting mechanism and evaluate its performance on various tasks, including language modeling, text generation, and question answering. Investigate the interactions between the forgetting mechanism and other model components, such as the attention mechanism.",
+        "Name": "memory_augmented_transformers",
+        "Title": "Memory-Augmented Transformers: Enhancing Language Models with External Memory Modules",
+        "Experiment": "Integrate a simple memory buffer into the GPT architecture, capable of storing a fixed number of past representations. Modify the forward function to include memory read/write operations. Implement criteria for selecting which representations to store, such as based on attention weights. Evaluate the impact on performance for tasks with long-range dependencies and rare event recall. Compare with baseline models to assess improvements.",
         "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "curiosity_driven_gpt",
-        "Title": "Curiosity-Driven Language Modeling: Exploring Novel Patterns in Input Data",
-        "Experiment": "Modify the attention mechanism to incorporate a curiosity-driven component, which encourages the model to explore and learn from novel or uncertain patterns in the input data. Introduce a new objective function that rewards the model for discovering new patterns. Use interpretable techniques to analyze the attention weights and understand what the model is focusing on.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "semantic_drift_analysis",
-        "Title": "Semantic Drift Analysis in Language Models: A Study on Temporal Changes in Text",
-        "Experiment": "Modify the `generate` function to produce text at different time steps. Use Latent Dirichlet Allocation (LDA) to identify changes in the topics or themes discussed in the generated text over time. Compare the model's performance on different datasets from different time periods.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "syntactic_complexity_aware_gpt",
-        "Title": "Syntactic Complexity-Aware GPT: Adapting Attention to Syntactic Complexity",
-        "Experiment": "Modify the attention mechanism to incorporate a syntactic complexity estimation module. The module will predict the syntactic complexity of the input text based on features such as sentence length, clause density, and phrase structure. The estimated syntactic complexity will then be used to adjust the attention weights in the model, with more attention allocated to complex or difficult input texts. Evaluate the performance of the modified model on language modeling tasks using a dataset with varying levels of syntactic complexity.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "entity_relationship_gpt",
-        "Title": "Entity Relationship-Augmented GPT: Improving Reasoning about Entities and Relationships",
-        "Experiment": "Train an entity relationship extraction module to extract relationships between entities mentioned in the text. Integrate this module into the GPT model and evaluate its performance on tasks such as question answering, text classification, and entity disambiguation.",
-        "Interestingness": 8,
-        "Feasibility": 9,
+        "Feasibility": 6,
         "Novelty": 8,
         "novel": true
     },
     {
-        "Name": "meta_forgetting_gpt",
-        "Title": "Meta-Forgetting in Language Models: A Study on Intentional Forgetting for Improved Generalization",
-        "Experiment": "Modify the training loop to incorporate a regularization term (L1 or L2 penalty on model weights) that penalizes the model for remembering certain patterns or information. Use a validation set to evaluate the model's performance on unseen data and adjust the forgetting mechanism using a hyperparameter that controls the strength of the regularization term.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "domain_invariant_reps",
-        "Title": "Learning Domain-Invariant Representations for Language Modeling",
-        "Experiment": "Modify the language model to learn domain-invariant representations by adding a domain-invariant loss function or using domain-adversarial training. Evaluate the model on a benchmark dataset and measure its ability to adapt to new domains.",
+        "Name": "cross_domain_mixing",
+        "Title": "Cross-Domain Mixing: Enhancing Model Robustness with Diverse Data Augmentation",
+        "Experiment": "Modify the get_batch function to allow for the mixing of samples from different datasets within a single batch. Implement a mechanism to control the mixing ratio dynamically during training. Adjust the training loop to accommodate the variability in input data. Evaluate the model's performance and generalization capabilities compared to baseline models trained on individual datasets. Assess improvements in robustness to overfitting and adaptability to unseen data.",
         "Interestingness": 8,
         "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "information_density_aware_gpt",
-        "Title": "Information Density-Aware GPT: Adapting Attention to Information Density",
-        "Experiment": "Modify the GPT model to incorporate an information density estimation module. The module will predict the information density of the input text based on features such as sentence length, entity frequency, and semantic complexity. The estimated information density will then be used to adjust the attention weights in the model, with more attention allocated to dense or complex input texts. Evaluate the model's performance on language modeling tasks using a dataset with varying levels of information density.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "syntactic_complexity_aware_gpt",
-        "Title": "Syntactic Complexity-Aware GPT: Adapting Attention to Syntactic Complexity",
-        "Experiment": "Modify the GPT model to incorporate a syntactic complexity estimation module using the Flesch-Kincaid readability test. The estimated syntactic complexity will be used to adjust the attention weights in the model, with more attention allocated to complex or difficult input texts. Evaluate the model's performance on language modeling tasks using a dataset with varying levels of syntactic complexity.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "cognitive_load_aware_gpt",
-        "Title": "Cognitive Load-Aware GPT: Adapting Attention to Cognitive Load",
-        "Experiment": "Modify the GPT model to incorporate a cognitive load estimation module. This module will predict the cognitive load of the input text based on measurable features such as complex vocabulary frequency and ambiguous syntax presence. The estimated cognitive load will then be used to adjust the attention weights in the model, with more attention allocated to input texts that are predicted to have a higher cognitive load.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "contrastive_forgetting_gpt",
-        "Title": "Contrastive Forgetting in Language Models: Preserving General Knowledge while Forgetting Domain-Specific Patterns",
-        "Experiment": "Modify the training loop to incorporate a contrastive forgetting loss function that focuses on forgetting domain-specific patterns. Use a combination of metrics, including perplexity, accuracy, and novelty scores, to evaluate the model's performance on a specific task such as text generation.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
+        "Novelty": 7,
         "novel": true
     }
 ]
\ No newline at end of file
diff --git a/templates/nanoGPT_lite/ideas.json b/templates/nanoGPT_lite/ideas.json
index 5458d98..62af1f1 100644
--- a/templates/nanoGPT_lite/ideas.json
+++ b/templates/nanoGPT_lite/ideas.json
@@ -5,8 +5,7 @@
         "Experiment": "Modify the model to dynamically adjust its block size during training, starting with a smaller block size and gradually increasing it. This could potentially lead to faster initial training and better long-range dependency learning.",
         "Interestingness": 6,
         "Feasibility": 4,
-        "Novelty": 4,
-        "novel": true
+        "Novelty": 4
     },
     {
         "Name": "layerwise_learning_rates",
@@ -14,457 +13,22 @@
         "Experiment": "Implement layer-wise learning rates, where each transformer layer has its own learning rate. Modify the configure_optimizers function to assign different learning rates to different layers, with deeper layers having lower learning rates. Compare the training dynamics, convergence speed, and final performance with the baseline model.",
         "Interestingness": 4,
         "Feasibility": 6,
-        "Novelty": 2,
-        "novel": true
+        "Novelty": 2
     },
     {
-        "Name": "attention_diversity_regularization",
-        "Title": "Attention Diversity Regularization: Encouraging Diverse Context Window Utilization in Transformers",
-        "Experiment": "Modify the loss function to include a regularization term that encourages diversity in the attention weights, using a measure such as entropy or the ratio of the attention weights to their maximum value. Introduce a hyperparameter to control the strength of the regularization term. Compare the model's performance on tasks that require long-range dependency modeling with and without the regularization term.",
+        "Name": "blended_context_windows",
+        "Title": "Blended Context Windows: Enhancing Context-Sensitive Token Representation in Language Models",
+        "Experiment": "Implement a mechanism to blend information from different context windows (e.g., short and long) during the forward pass. Modify the model to include an additional attention mechanism that processes different segments of the input at varying granularity levels and combines the outputs. Compare the training dynamics, convergence speed, and final performance with the baseline model.",
         "Interestingness": 7,
         "Feasibility": 6,
-        "Novelty": 5,
-        "novel": true
+        "Novelty": 5
     },
     {
-        "Name": "ntm_augmented_transformer",
-        "Title": "Neural Turing Machine-Augmented Transformer: Improving Text Generation with External Memory",
-        "Experiment": "Implement a fixed-size external memory module that stores and retrieves information through attention mechanisms, and apply the model to the task of text generation. Evaluate the effectiveness of the model and compare it to other approaches.",
+        "Name": "adaptive_dropout",
+        "Title": "Adaptive Dropout Rates: Dynamic Regularization for Enhanced Model Training",
+        "Experiment": "Modify the CausalSelfAttention and MLP classes to accept a dynamic dropout rate. Implement a linear schedule to adjust the dropout rate from a higher initial value to a lower value over the course of training. Compare the training dynamics, convergence speed, and final performance with the baseline model.",
         "Interestingness": 8,
         "Feasibility": 7,
-        "Novelty": 6,
-        "novel": false
-    },
-    {
-        "Name": "uncertainty_based_filtering",
-        "Title": "Uncertainty-Based Filtering: Reducing Hallucinations in Text Generation by Selecting High-Certainty Predictions",
-        "Experiment": "Modify the forward function of the GPT class to output a probability distribution over the possible next tokens. Compute a measure of uncertainty (e.g. entropy or variance) from this distribution, and use it to filter out predictions where the model is highly uncertain. Evaluate the effect of this filtering on the frequency of hallucinations in the generated text.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 6,
-        "novel": true
-    },
-    {
-        "Name": "targeted_knowledge_distillation",
-        "Title": "Targeted Knowledge Distillation for Transformer-Based Language Models: A Study on Distilling Specific Aspects of Model Behavior",
-        "Experiment": "Modify the GPT model to create a smaller student model with fewer layers and/or smaller embedding dimensions. Train the student model to mimic specific aspects of the teacher model's behavior, such as next token prediction or coherent text generation. Explore different distillation techniques, including attention-based distillation and layer-wise distillation.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "fine_tuning_gpt",
-        "Title": "Fine-Tuning for Task Adaptation: A Study on Adapting Pre-Trained GPT Models to New Tasks",
-        "Experiment": "Fine-tune the pre-trained GPT model on a small amount of task-specific data, using a standard supervised learning objective. Evaluate the effectiveness of this approach on a range of tasks and datasets, using metrics such as accuracy and perplexity.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 6,
-        "novel": false
-    },
-    {
-        "Name": "training_data_ordering",
-        "Title": "The Impact of Training Data Ordering on Language Model Performance",
-        "Experiment": "Modify the get_batch function to create batches with different ordering schemes, such as randomizing the order of the training data or prioritizing more recent text. Evaluate the model's performance on these batches using metrics such as perplexity, accuracy, or F1-score, and repeat the experiment on multiple datasets.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "memory_buffer_transformer",
-        "Title": "Memory Buffer Transformer: Improving Long-Range Dependency Modeling with a Simple Memory Mechanism",
-        "Experiment": "Modify the GPT model to include a fixed-size memory buffer that stores the most recent input tokens. Use a modified attention mechanism to incorporate the memory buffer into the model's predictions. Evaluate the impact of memory buffer size on model performance.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "meta_attention_gpt",
-        "Title": "Meta-Learning for Adaptive Attention in GPT Models",
-        "Experiment": "Modify the GPT model to include a meta-learning component that adapts the model's attention mechanism to new tasks and datasets. Train the meta-learning component using an episodic training protocol with a limited number of examples per task, and evaluate the model's performance on a diverse range of tasks and datasets.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "word_dropout_auxiliary_task",
-        "Title": "Word Dropout Auxiliary Task: Improving Language Understanding through Multi-Task Learning",
-        "Experiment": "Modify the training loop to include a word dropout auxiliary task, where a certain percentage of words in the input text are randomly replaced with a [MASK] token. Train the model to reconstruct the original text by predicting the missing words, in parallel with the primary language modeling task.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "temporal_regularization",
-        "Title": "Temporal Regularization for Mitigating Catastrophic Forgetting in Language Models",
-        "Experiment": "Modify the training loop to include a temporal regularization term that encourages the model to maintain consistency in its predictions over time. Add a L1 or L2 penalty term to the loss function that measures the difference between the model's predictions at different time steps.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "graph_augmented_gpt",
-        "Title": "Graph-Augmented GPT for Improved Entity Relationship Modeling",
-        "Experiment": "Modify the GPT model to incorporate a graph-based representation of entity relationships, using a graph convolutional network (GCN) or graph attention network (GAT) to augment the existing attention mechanisms.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "bias_aware_gpt",
-        "Title": "Bias-Aware GPT: A Self-Aware Language Model for Mitigating Biases",
-        "Experiment": "Modify the GPT model to include a bias detection mechanism. This could involve training a separate module to identify biased language or using existing techniques such as adversarial training. Evaluate the effectiveness of the bias detection mechanism using the Bias in Bios dataset.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "multi_objective_gpt",
-        "Title": "Multi-Objective Optimization for GPT Models: A Study on Language Modeling and Sentiment Analysis",
-        "Experiment": "Modify the forward function of the GPT class to output predictions for language modeling and sentiment analysis. Define separate optimizers for each task and modify the configure_optimizers function to use a weighted sum of the individual task losses. Use a subset of the training data with sentiment annotations for the sentiment analysis task.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "attention_dropout_transformer",
-        "Title": "Attention Dropout Transformer: Regularizing the Model with Targeted Dropout",
-        "Experiment": "Modify the transformer model to use attention dropout, which randomly drops out attention weights during training. Investigate the use of attention dropout in combination with other regularization techniques, such as dropout and weight decay. Evaluate the model's performance on language modeling and text classification tasks, and compare the results with the baseline model.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "domain_knowledge_graph_gpt",
-        "Title": "Domain-Specific Knowledge Graph-Augmented GPT for Improved Reasoning and Inference",
-        "Experiment": "Modify the GPT model to incorporate a pre-constructed domain-specific knowledge graph. Use a graph attention network (GAT) to integrate the knowledge graph into the model's attention mechanism. Evaluate the model's performance on tasks that require reasoning and inference in the chosen domain.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "difficulty_aware_sampling",
-        "Title": "Difficulty-Aware Sampling for Language Modeling: A Study on Dynamic Learning Objectives",
-        "Experiment": "Modify the training loop to use a difficulty-aware sampling strategy for the training data. Assign a difficulty score to each data point and sample them based on their difficulty, with a bias towards the more challenging ones. Evaluate the effectiveness of this approach using a robust set of metrics.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "discrete_time_echo_state_gpt",
-        "Title": "Discrete-Time Echo State Networks for Efficient Temporal Modeling in GPT",
-        "Experiment": "Replace the existing RNN layers in the GPT model with DTESN layers. Explore using simplified versions of the DTESN layers, such as sparse or pruned DTESNs. Combine the DTESN layers with a hierarchical attention framework to attend to different levels of abstraction in the input data.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "input_complexity_adaptation",
-        "Title": "Input Complexity Adaptation for Efficient Language Modeling",
-        "Experiment": "Modify the attention mechanism to adapt based on input complexity, measured using perplexity or entropy. Evaluate the model's performance on complex tasks and compare the results with the baseline model.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": false
-    },
-    {
-        "Name": "linguistic_complexity_manipulation",
-        "Title": "Linguistic Complexity Manipulation for Language Models: A Study on Performance and Generalization",
-        "Experiment": "Modify the input data to increase or decrease its linguistic complexity, such as by adding or removing complex syntactic structures, idiomatic expressions, or domain-specific vocabulary. Introduce a linguistic complexity-aware objective function to penalize the model for producing outputs that exceed a certain level of linguistic complexity. Evaluate the model's performance on a range of tasks, including language modeling, text classification, and question answering.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "temporal_knowledge_forgetting_gpt",
-        "Title": "Temporal Knowledge Forgetting in Language Models: A Study on Adapting to Sudden Changes in Data Distributions",
-        "Experiment": "Modify the GPT model to incorporate a temporal knowledge forgetting mechanism, where the model intentionally forgets knowledge that is no longer relevant or useful due to sudden changes in the data distribution. Introduce a new objective function that encourages the model to forget outdated knowledge, or modify the attention mechanism to focus on more recent information. Evaluate the model's performance on tasks that require adaptability to sudden changes in the data distribution.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "monte_carlo_confidence_aware_gpt",
-        "Title": "Monte Carlo Confidence-Aware GPT: Estimating Uncertainty via Dropout",
-        "Experiment": "Modify the GPT model to use Monte Carlo dropout to estimate the model's uncertainty. Train the model with dropout and then use the dropout weights to estimate the model's uncertainty at test time. Use the estimated uncertainty to modulate the loss function and improve the model's performance.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "calibrated_confidence_aware_gpt",
-        "Title": "Calibrated Confidence-Aware GPT: Estimating Uncertainty in Language Modeling",
-        "Experiment": "Modify the GPT model to output a confidence score along with its predictions. Add a new output layer to estimate the model's confidence in its predictions. Incorporate a calibration mechanism, such as temperature scaling or Platt scaling, to improve the accuracy of the confidence estimates. Add a robustness regularization term to the loss function to encourage conservative confidence estimates for out-of-distribution inputs.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "factual_knowledge_neurons",
-        "Title": "Identifying Factual Knowledge Neurons in Language Models",
-        "Experiment": "Modify the GPT model to include a knowledge neuron module that identifies which neurons are most responsible for storing factual information. Use techniques from explainable AI, such as saliency maps or feature importance scores, to identify the knowledge neurons. Evaluate the effectiveness of the knowledge neuron module on a benchmark such as TriviaQA or SQuAD.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "domain_adaptation_meta_learning",
-        "Title": "Domain Adaptation via Meta-Learning for Language Modeling",
-        "Experiment": "Modify the GPT model to include a meta-learning component that adapts the model to new domains or tasks. Train the model on a set of tasks that require it to adapt to new domains or tasks, and evaluate its performance on a range of language tasks, including language modeling and text classification.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "dual_scale_attention_gpt",
-        "Title": "Dual-Scale Attention in GPT: Capturing Long-Range Dependencies with Sparse Attention",
-        "Experiment": "Add a single additional attention layer to the GPT model that attends to a larger context window than the existing attention mechanism. Use a sparse attention mechanism, such as sparse self-attention or axial attention, to reduce computational complexity.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "multimodal_emotionally_intelligent_gpt",
-        "Title": "Multimodal Emotionally Intelligent GPT: Generating Text that Understands and Expresses Emotions",
-        "Experiment": "Modify the dataset to include emotional labels through sentiment analysis or emotional annotation. Use a multimodal approach to incorporate both text and emotional labels as input to the model. Fine-tune the model using a combination of language modeling and emotional intelligence objectives. Evaluate the model's performance using metrics such as emotional accuracy, empathy, and sentiment analysis.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "availability_heuristic_gpt",
-        "Title": "Availability Heuristic-Aware GPT: Simulating Human-Like Conversational Flow in Language Generation",
-        "Experiment": "Modify the GPT model's attention mechanism to incorporate the availability heuristic. Introduce a weighted attention layer that prioritizes recent or frequent events, and evaluate the generated text's conversational flow and coherence using a set of custom metrics.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "interpretable_dynamic_attention_gpt",
-        "Title": "Interpretable Dynamic Attention GPT: A Multi-Task Learning Approach to Adaptive Context Window Size",
-        "Experiment": "Modify the existing GPT model to incorporate a dynamic attention mechanism that uses a learned controller to adaptively adjust the context window size. Train the controller using a multi-task learning approach, where it is trained to predict both attention weights and auxiliary tasks such as part-of-speech tagging or named entity recognition. Evaluate the performance of the modified model on a range of tasks that require different types of attention.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "recency_effect_gpt",
-        "Title": "Recency Effect-Aware GPT: Simulating Human-Like Decision-Making in Language Generation",
-        "Experiment": "Modify the attention mechanism in the GPT model to use a weighted attention layer that prioritizes recent input tokens, incorporating the recency effect. Evaluate the generated text's perplexity and BLEU score to assess the impact of the recency effect on the language model's performance.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "idiomatic_gpt",
-        "Title": "Idiomatic GPT: A Language Model with Idiom Recognition and Generation",
-        "Experiment": "Modify the GPT model to include an idiom recognition module that uses a combination of attention mechanisms and knowledge graphs to identify and generate idiomatic expressions.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "selective_forgetting_gpt",
-        "Title": "Selective Forgetting in GPT: A Novel Approach to Memory Consolidation",
-        "Experiment": "Modify the attention mechanism in the GPT model to include a forgetting component that gradually reduces the importance of older information over time. Evaluate the effectiveness of this mechanism using metrics such as recall from a longer context window or reduction in catastrophic forgetting.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "syntactic_complexity_analysis",
-        "Title": "Syntactic Complexity Analysis in Language Models",
-        "Experiment": "Modify the training data to include a syntactic complexity metric, such as the average sentence length or the number of clauses per sentence. Analyze the model's performance on different subsets of the training data with varying levels of syntactic complexity, compared to a control group trained on a random subset of the data.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "linguistic_difficulty_gpt",
-        "Title": "Linguistic Difficulty-Aware GPT: Using Linguistic Features to Predict Input Text Complexity",
-        "Experiment": "Add a linguistic difficulty estimation module to the GPT model, which predicts the difficulty of the input text based on linguistic features such as sentence length, syntactic complexity, and semantic ambiguity. Use the estimated difficulty to adjust the attention weights in the model, with more attention allocated to complex or difficult input texts. Evaluate the performance of the modified model on a range of input texts with varying levels of linguistic complexity.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "linguistic_complexity_aware_gpt",
-        "Title": "Linguistic Complexity-Aware GPT: Improving Performance on Complex Input Texts",
-        "Experiment": "Modify the attention mechanism to incorporate a linguistic complexity estimation module. Evaluate the performance of the modified model on language modeling tasks with varying levels of linguistic complexity.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "recency_effect_gpt",
-        "Title": "Incorporating the Recency Effect into Language Models for More Coherent and Context-Dependent Text Generation",
-        "Experiment": "Modify the attention mechanism in the GPT model to prioritize recent input tokens, using a new weighting scheme that decays the importance of input tokens over time. Evaluate the language model's performance on text generation tasks using metrics that specifically evaluate coherence and context-dependence.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "dynamic_attention_gpt",
-        "Title": "Dynamic Attention GPT: Adapting to Varying Levels of Cognitive Load",
-        "Experiment": "Modify the GPT model to use a dynamic attention mechanism that adjusts its attention weights based on the average sentence length of the input text. Evaluate the performance of the modified model on language modeling tasks such as text generation and language translation.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": false
-    },
-    {
-        "Name": "primacy_effect_gpt",
-        "Title": "The Primacy Effect in Language Models: Exploring the Impact on Text Completion",
-        "Experiment": "Modify the GPT model to introduce a primacy effect, where the model is biased towards generating text that is overly influenced by the first few tokens of the input. Evaluate the performance of the modified model on a text completion task, using metrics such as perplexity, BLEU score, and novelty score.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 7,
-        "novel": true
-    },
-    {
-        "Name": "novelty_conditioned_gpt",
-        "Title": "Novelty-Conditioned GPT: Adjusting Language Generation based on Input Novelty",
-        "Experiment": "Train the GPT model to detect novel input sequences and adjust its language generation accordingly. Use a novelty detection module to identify novel input sequences and modify the output generation to be more diverse and creative when novelty is detected.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "availability_heuristic_gpt",
-        "Title": "Availability Heuristic in GPT: Exploring the Impact of Recent Information on Language Generation",
-        "Experiment": "Modify the attention mechanism in the GPT model to give more weight to recently or frequently encountered information. Evaluate the performance of the modified model on a range of tasks, including language modeling, text generation, and text classification.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "frequency_based_forgetting_gpt",
-        "Title": "Frequency-Based Forgetting in GPT: Exploring the Impact of Forgetting on Language Model Performance",
-        "Experiment": "Modify the GPT model to incorporate a frequency-based forgetting mechanism that forgets input tokens during training. Train the model with this forgetting mechanism and evaluate its performance on various tasks, including language modeling, text generation, and question answering. Investigate the interactions between the forgetting mechanism and other model components, such as the attention mechanism.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "curiosity_driven_gpt",
-        "Title": "Curiosity-Driven Language Modeling: Exploring Novel Patterns in Input Data",
-        "Experiment": "Modify the attention mechanism to incorporate a curiosity-driven component, which encourages the model to explore and learn from novel or uncertain patterns in the input data. Introduce a new objective function that rewards the model for discovering new patterns. Use interpretable techniques to analyze the attention weights and understand what the model is focusing on.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "semantic_drift_analysis",
-        "Title": "Semantic Drift Analysis in Language Models: A Study on Temporal Changes in Text",
-        "Experiment": "Modify the `generate` function to produce text at different time steps. Use Latent Dirichlet Allocation (LDA) to identify changes in the topics or themes discussed in the generated text over time. Compare the model's performance on different datasets from different time periods.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "syntactic_complexity_aware_gpt",
-        "Title": "Syntactic Complexity-Aware GPT: Adapting Attention to Syntactic Complexity",
-        "Experiment": "Modify the attention mechanism to incorporate a syntactic complexity estimation module. The module will predict the syntactic complexity of the input text based on features such as sentence length, clause density, and phrase structure. The estimated syntactic complexity will then be used to adjust the attention weights in the model, with more attention allocated to complex or difficult input texts. Evaluate the performance of the modified model on language modeling tasks using a dataset with varying levels of syntactic complexity.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "entity_relationship_gpt",
-        "Title": "Entity Relationship-Augmented GPT: Improving Reasoning about Entities and Relationships",
-        "Experiment": "Train an entity relationship extraction module to extract relationships between entities mentioned in the text. Integrate this module into the GPT model and evaluate its performance on tasks such as question answering, text classification, and entity disambiguation.",
-        "Interestingness": 8,
-        "Feasibility": 9,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "meta_forgetting_gpt",
-        "Title": "Meta-Forgetting in Language Models: A Study on Intentional Forgetting for Improved Generalization",
-        "Experiment": "Modify the training loop to incorporate a regularization term (L1 or L2 penalty on model weights) that penalizes the model for remembering certain patterns or information. Use a validation set to evaluate the model's performance on unseen data and adjust the forgetting mechanism using a hyperparameter that controls the strength of the regularization term.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "domain_invariant_reps",
-        "Title": "Learning Domain-Invariant Representations for Language Modeling",
-        "Experiment": "Modify the language model to learn domain-invariant representations by adding a domain-invariant loss function or using domain-adversarial training. Evaluate the model on a benchmark dataset and measure its ability to adapt to new domains.",
-        "Interestingness": 8,
-        "Feasibility": 7,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "information_density_aware_gpt",
-        "Title": "Information Density-Aware GPT: Adapting Attention to Information Density",
-        "Experiment": "Modify the GPT model to incorporate an information density estimation module. The module will predict the information density of the input text based on features such as sentence length, entity frequency, and semantic complexity. The estimated information density will then be used to adjust the attention weights in the model, with more attention allocated to dense or complex input texts. Evaluate the model's performance on language modeling tasks using a dataset with varying levels of information density.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "syntactic_complexity_aware_gpt",
-        "Title": "Syntactic Complexity-Aware GPT: Adapting Attention to Syntactic Complexity",
-        "Experiment": "Modify the GPT model to incorporate a syntactic complexity estimation module using the Flesch-Kincaid readability test. The estimated syntactic complexity will be used to adjust the attention weights in the model, with more attention allocated to complex or difficult input texts. Evaluate the model's performance on language modeling tasks using a dataset with varying levels of syntactic complexity.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
-    },
-    {
-        "Name": "cognitive_load_aware_gpt",
-        "Title": "Cognitive Load-Aware GPT: Adapting Attention to Cognitive Load",
-        "Experiment": "Modify the GPT model to incorporate a cognitive load estimation module. This module will predict the cognitive load of the input text based on measurable features such as complex vocabulary frequency and ambiguous syntax presence. The estimated cognitive load will then be used to adjust the attention weights in the model, with more attention allocated to input texts that are predicted to have a higher cognitive load.",
-        "Interestingness": 9,
-        "Feasibility": 8,
-        "Novelty": 9,
-        "novel": true
-    },
-    {
-        "Name": "contrastive_forgetting_gpt",
-        "Title": "Contrastive Forgetting in Language Models: Preserving General Knowledge while Forgetting Domain-Specific Patterns",
-        "Experiment": "Modify the training loop to incorporate a contrastive forgetting loss function that focuses on forgetting domain-specific patterns. Use a combination of metrics, including perplexity, accuracy, and novelty scores, to evaluate the model's performance on a specific task such as text generation.",
-        "Interestingness": 8,
-        "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
+        "Novelty": 6
     }
 ]
\ No newline at end of file
diff --git a/templates/seir/experiment.py b/templates/seir/experiment.py
index 520ee1f..5b2ae06 100644
--- a/templates/seir/experiment.py
+++ b/templates/seir/experiment.py
@@ -3,6 +3,8 @@ import json
 import os
 
 import numpy as np
+import weave
+
 from scipy.integrate import odeint
 
 # -----------------------------------------------------------------------------
@@ -19,7 +21,7 @@ if __name__ == "__main__":
     out_dir = args.out_dir
     os.makedirs(out_dir, exist_ok=True)
 
-
+    @weave.op()
     def seir_eq(v, t, beta, lp, ip):
         """Differential equation of SEIR model
         v: [S, E, I, R] Distribution of people in each state
diff --git a/templates/seir/ideas.json b/templates/seir/ideas.json
index 9e506c0..6c423aa 100644
--- a/templates/seir/ideas.json
+++ b/templates/seir/ideas.json
@@ -9,21 +9,30 @@
         "novel": true
     },
     {
-        "Name": "vaccination_strategy_seir",
-        "Title": "Incorporating Vaccination Strategies into SEIR Dynamics",
-        "Experiment": "Modify the seir_eq function to add a vaccination compartment (V). Implement various vaccination strategies with defined vaccination rates (e.g., 0.1% per day) and specify vaccine efficacy duration (e.g., 6 months). Conduct sensitivity analyses to assess how varying vaccination rates and durations affect peak infections and total infections over time. Compare immediate, phased, and delayed vaccination strategies in terms of their effectiveness in controlling the outbreak.",
+        "Name": "network_influence_seir",
+        "Title": "Investigating the Influence of Social Network Structures on SEIR Dynamics",
+        "Experiment": "Modify the seir_eq function to implement a specific network structure, such as scale-free networks, to simulate disease spread. Analyze how this network type affects peak infection rates and total infections compared to a simple random network. Results will be collected by running simulations on both network types and comparing the outcomes.",
         "Interestingness": 9,
         "Feasibility": 8,
-        "Novelty": 8,
-        "novel": true
+        "Novelty": 9,
+        "novel": false
     },
     {
-        "Name": "dynamic_social_distancing_seir",
-        "Title": "Modeling Dynamic Social Distancing Responses in SEIR Dynamics",
-        "Experiment": "Modify the seir_eq function to include a social distancing factor that reduces the infection rate based on the number of infections. Define three levels of social distancing (mild, moderate, strict) triggered at specific infection thresholds. Analyze the outcomes in terms of peak infections, total infections, and the duration of the epidemic, comparing results with and without these distancing measures.",
+        "Name": "uniform_vaccination_seir",
+        "Title": "Assessing the Impact of Uniform Vaccination on SEIR Dynamics",
+        "Experiment": "Modify the seir_eq function to reduce the susceptibility of a fixed percentage of the susceptible population due to vaccination. Analyze the effects of this uniform vaccination on peak infections and total infections compared to the baseline SEIR model without vaccination. Perform simulations with a range of vaccination rates (e.g., 10%, 20%, 30%) to observe the impact on disease dynamics.",
         "Interestingness": 9,
-        "Feasibility": 9,
-        "Novelty": 9,
-        "novel": true
+        "Feasibility": 8,
+        "Novelty": 7,
+        "novel": false
+    },
+    {
+        "Name": "stochastic_seir_model",
+        "Title": "Incorporating Stochastic Processes in SEIR Dynamics",
+        "Experiment": "Modify the seir_eq function to introduce random fluctuations in the infection rate drawn from a defined probability distribution (e.g., Gaussian) while keeping the recovery rate constant. Run multiple simulations to analyze how these variations impact peak infections and total infections compared to the baseline deterministic SEIR model.",
+        "Interestingness": 9,
+        "Feasibility": 8,
+        "Novelty": 8,
+        "novel": false
     }
 ]
\ No newline at end of file
